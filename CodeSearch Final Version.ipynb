{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66b2295",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7b3501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/snandula/.local/lib/python3.9/site-packages (2.14.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: xxhash in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: multiprocess in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/snandula/.local/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/snandula/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/snandula/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/snandula/.local/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets) (2.0.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/snandula/.local/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/snandula/.local/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c06b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faiss-cpu in /home/snandula/.local/lib/python3.9/site-packages (1.7.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/snandula/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: sentencepiece in /home/snandula/.local/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/snandula/.local/lib/python3.9/site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: tqdm in /home/snandula/.local/lib/python3.9/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/snandula/.local/lib/python3.9/site-packages (from sentence-transformers) (4.34.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from sentence-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: fsspec in /home/snandula/.local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (1.8)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.0)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (15.0.7)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/snandula/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/snandula/.local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.9/site-packages (from networkx->torch>=1.6.0->sentence-transformers) (5.0.9)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea02f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"code_search_net\", \"ruby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29006d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c73f85",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5471bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = dataset['train']['func_documentation_string']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8c327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('BAAI/bge-base-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e0c5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0da703",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b98a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(model.get_sentence_embedding_dimension()))\n",
    "index.add_with_ids(encoded_data, np.array(range(0, len(documents))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e4c2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serializing index to export it across different host\n",
    "faiss.write_index(index, 'sample_documents')\n",
    "\n",
    "#de-serializing the index\n",
    "index = faiss.read_index('sample_documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36615516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, model, index):\n",
    "    t = time.time()\n",
    "    query_vector = model.encode([query])\n",
    "    \n",
    "    top_k = index.search(query_vector, index.ntotal)\n",
    "    \n",
    "    document_ids = top_k[1].tolist()[0]\n",
    "    scores = top_k[0].tolist()[0]\n",
    "    \n",
    "    results = [(doc_id, score) for doc_id, score in zip(document_ids, scores)]\n",
    "    \n",
    "    results.sort(key=lambda x: x[0])\n",
    "    \n",
    "    semantic_scores = [i[1] for i in results]\n",
    "\n",
    "    max_score = max(semantic_scores)\n",
    "    normalized_semantic_scores = [score / max_score for score in semantic_scores]\n",
    "    normalized_semantic_scores\n",
    "    \n",
    "    return normalized_semantic_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1d0897",
   "metadata": {},
   "source": [
    "## BM-25 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf5f4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_tokens = dataset['train']['func_code_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d9d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rank_bm25 in /home/snandula/.local/lib/python3.9/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rank_bm25) (1.22.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7c44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd5d4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(func_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c226628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(user_input, bm25):\n",
    "    \n",
    "    doc_scores = bm25.get_scores(user_input)\n",
    "    max_score = max(doc_scores)\n",
    "\n",
    "    # normalize BM25 scores\n",
    "    normalized_doc_scores = [score / max_score for score in doc_scores]\n",
    "    \n",
    "    return normalized_doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31fadd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17035165796158439,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2766019273510221,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.32532439512781636,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.33942422785024967,\n",
       " 0.3578174553670116,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.44348471508474613,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.38938086407846945,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25659805997544144,\n",
       " 0.24528879085323058,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.27395364812492984,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2047839257202112,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.10861181211593662,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2595867510743289,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1194981267616738,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2798205594777485,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17190772564766713,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.36944070996389233,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.27566258171331876,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1460039255625308,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.21282416050886366,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1011483967391883,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3197860822441697,\n",
       " 0.0,\n",
       " 0.2766019273510221,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.18708141896604213,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.34803573095802975,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_search(\"max\", bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc699e7",
   "metadata": {},
   "source": [
    "## Combined Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "187de7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quartiles(data):\n",
    "    filtered_sorted_data = sorted([x for x in data if x != 0])\n",
    "    n = len(filtered_sorted_data)\n",
    "    if n == 0:\n",
    "        return [0 for _ in data]\n",
    "    q1 = filtered_sorted_data[int(n * 0.25) - 1]\n",
    "    q2 = filtered_sorted_data[int(n * 0.5) - 1]\n",
    "    q3 = filtered_sorted_data[int(n * 0.75) - 1]\n",
    "    quartiles = []\n",
    "    \n",
    "    for value in data:\n",
    "        if value <= q1:\n",
    "            quartiles.append(0)\n",
    "        elif value <= q2:\n",
    "            quartiles.append(1)\n",
    "        elif value <= q3:\n",
    "            quartiles.append(2)\n",
    "        else:\n",
    "            quartiles.append(3)\n",
    "    return quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06170e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_results(sem_weight, bm_weight, user_input):\n",
    "    sem = semantic_search(user_input, model, index)\n",
    "    bm = bm25_search(user_input, bm25)\n",
    "    weighted_sem = [i * sem_weight for i in sem]\n",
    "    weighted_bm = [i * bm_weight for i in bm]\n",
    "    weighted_avg = [weighted_sem[i]+ weighted_bm[i] for i in range(0, len(weighted_bm))]\n",
    "    sum_weight = sem_weight + bm_weight \n",
    "    weighted_avg_norm = [i/sum_weight for i in weighted_avg]\n",
    "    url = dataset[\"train\"]['func_code_url']\n",
    "    \n",
    "    if not weighted_avg_norm or np.isnan(weighted_avg_norm).any():\n",
    "        return {} \n",
    "    try:\n",
    "        labels = find_quartiles(weighted_avg_norm)\n",
    "        output_dict = {url[i]: labels[i] for i in range(len(weighted_avg_norm))}\n",
    "    except ValueError:\n",
    "        return {}\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53724e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(search_output, eval_dict):\n",
    "    inter = list(search_output.keys() & eval_dict.keys())\n",
    "    y_pred = [search_output[i] for i in search_output.keys() if i in inter]\n",
    "    y_true = [eval_dict[i] for i in eval_dict.keys() if i in inter]\n",
    "    if (len(y_true) <=1):\n",
    "        return None\n",
    "    if (len(y_pred) <=1):\n",
    "        return None\n",
    "        \n",
    "    y_true_nd = np.zeros(shape=(len(y_true), 4))\n",
    "    y_true_nd[np.arange(len( y_true)), y_true] = 1\n",
    "    y_pred_nd = np.zeros(shape=(len(y_true), 4))\n",
    "    y_pred_nd[np.arange(len( y_true)), y_pred] = 1\n",
    "    return ndcg_score(y_true_nd, y_pred_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "287f69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(\"annotationStore.csv\") \n",
    "eval_Ruby = eval_df[eval_df[\"Language\"] == \"Ruby\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd907bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_weights(sem_weight, bm_weight):\n",
    "    grouped_evals = eval_Ruby.groupby('Query').apply(lambda x: pd.Series(x.Relevance.values, index=x.GitHubUrl).to_dict())\n",
    "    ndcgs = []\n",
    "    search_results_cache = {}  \n",
    "\n",
    "    for query, evals in grouped_evals.items():\n",
    "        if (sem_weight, bm_weight, query) not in search_results_cache:\n",
    "            search_results_cache[(sem_weight, bm_weight, query)] = search_results(sem_weight, bm_weight, query) \n",
    "        our_search = search_results_cache[(sem_weight, bm_weight, query)]\n",
    "        ndcgs.append(ndcg(our_search, grouped_evals[query]))\n",
    "    filtered_scores = [s for s in ndcgs if s is not None]\n",
    "    return sum(filtered_scores)/len(filtered_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd98f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search():\n",
    "    best_precision = 0\n",
    "    best_weights = (0, 0)\n",
    "    sem_weight_range = (0, 1) \n",
    "    increment = 0.1\n",
    "    \n",
    "    for sem_weight in np.arange(*sem_weight_range, increment):\n",
    "        bm_weight = 1 - sem_weight\n",
    "        current_precision = find_best_weights(sem_weight, bm_weight)\n",
    "        if current_precision > best_precision:\n",
    "            best_precision = current_precision\n",
    "            best_weights = (sem_weight, bm_weight)\n",
    "\n",
    "    return best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1858e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c97de9",
   "metadata": {},
   "source": [
    "# End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae48c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end(best_weights):\n",
    "    grouped_evals = eval_Ruby.groupby('Query').apply(lambda x: pd.Series(x.Relevance.values, index=x.GitHubUrl).to_dict())\n",
    "\n",
    "    prec = []\n",
    "    search_results_cache = {}  \n",
    "\n",
    "    sem_weight, bm_weight = best_weights\n",
    "    \n",
    "    for query, evals in grouped_evals.items():\n",
    "        if (sem_weight, bm_weight, query) not in search_results_cache:\n",
    "            search_results_cache[(sem_weight, bm_weight, query)] = search_results(sem_weight, bm_weight, query)\n",
    "        \n",
    "        our_search = search_results_cache[(sem_weight, bm_weight, query)]\n",
    "        inter = set(evals.keys()) & set(our_search.keys())\n",
    "\n",
    "        if inter:\n",
    "            prec.append(ndcg(our_search, evals))\n",
    "        precs = [i for i in prec if i is not None]\n",
    "    return sum(precs) / len(precs) if precs else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40f74399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139194775382534"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_to_end(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbcc08",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efc7eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(best_weights, user_input):\n",
    "    sem_weight, bm_weight = best_weights\n",
    "    sem = semantic_search(user_input, model, index)\n",
    "    bm = bm25_search(user_input, bm25)\n",
    "    weighted_sem = [i * sem_weight for i in sem]\n",
    "    weighted_bm = [i * bm_weight for i in bm]\n",
    "    weighted_avg = [weighted_sem[i]+ weighted_bm[i] for i in range(0, len(weighted_bm))]\n",
    "    sum_weight = sem_weight + bm_weight \n",
    "    weighted_avg_norm = [i/sum_weight for i in weighted_avg]\n",
    "    url = []\n",
    "    function_name = []\n",
    "    doc_string = []\n",
    "    title =[]\n",
    "    top_10_docs = sorted(range(len(weighted_avg_norm)), key=lambda i: weighted_avg_norm[i], reverse=True)[:10]    \n",
    "    for i in top_10_docs:\n",
    "        function_name.append(dataset['train']['func_name'][i])\n",
    "        doc_string.append(dataset['train']['func_documentation_string'][i])\n",
    "        url.append(dataset[\"train\"]['func_code_url'][i])\n",
    "        \n",
    "    results_df = pd.DataFrame({'URL': url})\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3da755da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/ucnv/aviglitch/blob/0a1def0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/oleganza/btcruby/blob/0aa02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/SSSaaS/sssa-ruby/blob/df65d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/ruby-numo/numo-linalg/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/colbell/bitsa/blob/8b73c498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://github.com/ruby-numo/numo-linalg/blob/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://github.com/erichmenge/signed_form/blob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://github.com/sup-heliotrope/sup/blob/36f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://github.com/blotto/thermometer/blob/bb4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://github.com/wied03/opal-factory_girl/bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL\n",
       "0  https://github.com/ucnv/aviglitch/blob/0a1def0...\n",
       "1  https://github.com/oleganza/btcruby/blob/0aa02...\n",
       "2  https://github.com/SSSaaS/sssa-ruby/blob/df65d...\n",
       "3  https://github.com/ruby-numo/numo-linalg/blob/...\n",
       "4  https://github.com/colbell/bitsa/blob/8b73c498...\n",
       "5  https://github.com/ruby-numo/numo-linalg/blob/...\n",
       "6  https://github.com/erichmenge/signed_form/blob...\n",
       "7  https://github.com/sup-heliotrope/sup/blob/36f...\n",
       "8  https://github.com/blotto/thermometer/blob/bb4...\n",
       "9  https://github.com/wied03/opal-factory_girl/bl..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(best_weights, \"enumerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc58c25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
